/**
 * Cache Metrics Collection System
 * Comprehensive monitoring and analytics for cache performance
 */

import { EventEmitter } from 'events';
import { CachedSearchService } from '../services/search/CachedSearchService';
import { CacheService } from '../services/CacheService';
import { CacheMiddleware } from '../middleware/cacheMiddleware';
import { BatchDocumentRetriever } from '../services/search/BatchDocumentRetriever';

export interface MetricsConfig {
  enabled: boolean;
  collectionInterval: number;
  retentionPeriod: number; // Days
  aggregationLevels: ('minute' | 'hour' | 'day')[];
  alertThresholds: {
    hitRate: number;
    responseTime: number;
    errorRate: number;
    memoryUsage: number;
  };
  exportOptions: {
    enabled: boolean;
    formats: ('json' | 'csv' | 'prometheus')[];
    destination: string;
  };
}

export interface MetricPoint {
  timestamp: Date;
  metric: string;
  value: number;
  tags: Record<string, string>;
  source: string;
}

export interface AggregatedMetrics {
  timeframe: 'minute' | 'hour' | 'day';
  startTime: Date;
  endTime: Date;
  metrics: {
    cache: {
      hitRate: { min: number; max: number; avg: number; p95: number };
      responseTime: { min: number; max: number; avg: number; p95: number };
      throughput: { total: number; avg: number; peak: number };
      memoryUsage: { min: number; max: number; avg: number; current: number };
      errorRate: { min: number; max: number; avg: number };
    };
    search: {
      queries: { total: number; successful: number; failed: number };
      avgQueryTime: number;
      popularQueries: Array<{ query: string; count: number }>;
      categoryDistribution: Record<string, number>;
    };
    http: {
      requests: { total: number; hits: number; misses: number };
      bandwidth: { saved: number; total: number };
      compressionRatio: number;
    };
    batching: {
      batchedRequests: number;
      avgBatchSize: number;
      performanceGain: number;
    };
  };
}

export interface MetricsAlert {
  id: string;
  severity: 'info' | 'warning' | 'error' | 'critical';
  metric: string;
  threshold: number;
  currentValue: number;
  message: string;
  timestamp: Date;
  resolved?: boolean;
  resolvedAt?: Date;
}

export interface MetricsSummary {
  overall: {
    status: 'healthy' | 'degraded' | 'critical';
    score: number; // 0-100
    uptime: number;
  };
  performance: {
    hitRate: number;
    avgResponseTime: number;
    throughput: number;
    errorRate: number;
  };
  trends: {
    hitRateTrend: 'improving' | 'stable' | 'declining';
    responseTrend: 'improving' | 'stable' | 'declining';
    throughputTrend: 'increasing' | 'stable' | 'decreasing';
  };
  topIssues: string[];
  recommendations: string[];
}

/**
 * Comprehensive cache metrics collection and monitoring system
 */
export class CacheMetricsCollector extends EventEmitter {
  private config: MetricsConfig;
  private cachedSearchService: CachedSearchService;
  private cacheService: CacheService;
  private cacheMiddleware: CacheMiddleware;
  private batchRetriever: BatchDocumentRetriever;

  private metrics: MetricPoint[] = [];
  private aggregatedMetrics: Map<string, AggregatedMetrics> = new Map();
  private activeAlerts: Map<string, MetricsAlert> = new Map();

  private collectionTimer?: ReturnType<typeof setTimeout>;
  private aggregationTimer?: ReturnType<typeof setTimeout>;
  private isCollecting = false;
  private startTime: Date;\n\n  constructor(\n    cachedSearchService: CachedSearchService,\n    cacheService: CacheService,\n    cacheMiddleware: CacheMiddleware,\n    batchRetriever: BatchDocumentRetriever,\n    config?: Partial<MetricsConfig>\n  ) {\n    super();\n    \n    this.cachedSearchService = cachedSearchService;\n    this.cacheService = cacheService;\n    this.cacheMiddleware = cacheMiddleware;\n    this.batchRetriever = batchRetriever;\n    this.config = this.mergeConfig(config);\n    this.startTime = new Date();\n  }\n\n  /**\n   * Start metrics collection\n   */\n  start(): void {\n    if (!this.config.enabled) {\n      console.log('ðŸ“Š Cache metrics collection disabled');\n      return;\n    }\n\n    if (this.isCollecting) {\n      console.warn('Metrics collection already started');\n      return;\n    }\n\n    console.log('ðŸ“Š Starting cache metrics collection...');\n    \n    this.isCollecting = true;\n    \n    // Start periodic collection\n    this.collectionTimer = setInterval(() => {\n      this.collectMetrics().catch(error => {\n        console.error('Metrics collection failed:', error);\n        this.emit('error', error);\n      });\n    }, this.config.collectionInterval);\n    \n    // Start periodic aggregation\n    this.aggregationTimer = setInterval(() => {\n      this.aggregateMetrics().catch(error => {\n        console.error('Metrics aggregation failed:', error);\n      });\n    }, 60000); // Aggregate every minute\n    \n    // Initial collection\n    setTimeout(() => this.collectMetrics(), 1000);\n    \n    console.log('âœ… Cache metrics collection started');\n  }\n\n  /**\n   * Stop metrics collection\n   */\n  stop(): void {\n    if (!this.isCollecting) {\n      return;\n    }\n\n    console.log('ðŸ›‘ Stopping cache metrics collection...');\n    \n    this.isCollecting = false;\n    \n    if (this.collectionTimer) {\n      clearInterval(this.collectionTimer);\n      this.collectionTimer = undefined;\n    }\n    \n    if (this.aggregationTimer) {\n      clearInterval(this.aggregationTimer);\n      this.aggregationTimer = undefined;\n    }\n    \n    console.log('âœ… Cache metrics collection stopped');\n  }\n\n  /**\n   * Get current metrics summary\n   */\n  getSummary(): MetricsSummary {\n    const recentMetrics = this.getRecentMetrics(300000); // Last 5 minutes\n    \n    return {\n      overall: this.calculateOverallHealth(recentMetrics),\n      performance: this.calculatePerformanceMetrics(recentMetrics),\n      trends: this.calculateTrends(),\n      topIssues: this.getTopIssues(),\n      recommendations: this.generateRecommendations(recentMetrics)\n    };\n  }\n\n  /**\n   * Get metrics for a specific time range\n   */\n  getMetrics(\n    startTime: Date,\n    endTime: Date,\n    metric?: string\n  ): MetricPoint[] {\n    return this.metrics.filter(m => {\n      const timeMatch = m.timestamp >= startTime && m.timestamp <= endTime;\n      const metricMatch = !metric || m.metric === metric;\n      return timeMatch && metricMatch;\n    });\n  }\n\n  /**\n   * Get aggregated metrics\n   */\n  getAggregatedMetrics(\n    timeframe: 'minute' | 'hour' | 'day',\n    count: number = 24\n  ): AggregatedMetrics[] {\n    const key = timeframe;\n    const results: AggregatedMetrics[] = [];\n    \n    // Get most recent aggregated metrics\n    for (const [timestamp, metrics] of this.aggregatedMetrics) {\n      if (metrics.timeframe === timeframe) {\n        results.push(metrics);\n      }\n    }\n    \n    return results\n      .sort((a, b) => b.startTime.getTime() - a.startTime.getTime())\n      .slice(0, count);\n  }\n\n  /**\n   * Get active alerts\n   */\n  getActiveAlerts(): MetricsAlert[] {\n    return Array.from(this.activeAlerts.values()).filter(alert => !alert.resolved);\n  }\n\n  /**\n   * Get metrics in Prometheus format\n   */\n  getPrometheusMetrics(): string {\n    const recentMetrics = this.getRecentMetrics(60000); // Last minute\n    const lines: string[] = [];\n    \n    // Group metrics by name\n    const metricGroups = new Map<string, MetricPoint[]>();\n    \n    for (const metric of recentMetrics) {\n      if (!metricGroups.has(metric.metric)) {\n        metricGroups.set(metric.metric, []);\n      }\n      metricGroups.get(metric.metric)!.push(metric);\n    }\n    \n    // Convert to Prometheus format\n    for (const [metricName, points] of metricGroups) {\n      const latestPoint = points[points.length - 1];\n      \n      if (latestPoint) {\n        const labels = Object.entries(latestPoint.tags)\n          .map(([key, value]) => `${key}=\"${value}\"`)\n          .join(',');\n        \n        lines.push(`# TYPE cache_${metricName} gauge`);\n        lines.push(`cache_${metricName}{${labels}} ${latestPoint.value}`);\n      }\n    }\n    \n    return lines.join('\\n');\n  }\n\n  /**\n   * Export metrics to configured destinations\n   */\n  async exportMetrics(): Promise<void> {\n    if (!this.config.exportOptions.enabled) {\n      return;\n    }\n\n    const recentMetrics = this.getRecentMetrics(3600000); // Last hour\n    \n    for (const format of this.config.exportOptions.formats) {\n      try {\n        switch (format) {\n          case 'json':\n            await this.exportJSON(recentMetrics);\n            break;\n          case 'csv':\n            await this.exportCSV(recentMetrics);\n            break;\n          case 'prometheus':\n            await this.exportPrometheus();\n            break;\n        }\n      } catch (error) {\n        console.error(`Failed to export metrics in ${format} format:`, error);\n      }\n    }\n  }\n\n  /**\n   * Force metrics collection\n   */\n  async forceCollection(): Promise<void> {\n    await this.collectMetrics();\n  }\n\n  /**\n   * Clear old metrics data\n   */\n  cleanup(): void {\n    const cutoff = new Date(Date.now() - (this.config.retentionPeriod * 24 * 60 * 60 * 1000));\n    \n    // Remove old metric points\n    const originalLength = this.metrics.length;\n    this.metrics = this.metrics.filter(m => m.timestamp > cutoff);\n    \n    // Remove old aggregated metrics\n    for (const [key, metrics] of this.aggregatedMetrics) {\n      if (metrics.startTime < cutoff) {\n        this.aggregatedMetrics.delete(key);\n      }\n    }\n    \n    // Remove resolved alerts older than 24 hours\n    const alertCutoff = new Date(Date.now() - (24 * 60 * 60 * 1000));\n    for (const [key, alert] of this.activeAlerts) {\n      if (alert.resolved && alert.resolvedAt && alert.resolvedAt < alertCutoff) {\n        this.activeAlerts.delete(key);\n      }\n    }\n    \n    const removed = originalLength - this.metrics.length;\n    if (removed > 0) {\n      console.log(`ðŸ§¹ Cleaned up ${removed} old metric points`);\n    }\n  }\n\n  // =========================\n  // Private Implementation\n  // =========================\n\n  private mergeConfig(config?: Partial<MetricsConfig>): MetricsConfig {\n    return {\n      enabled: true,\n      collectionInterval: 30000, // 30 seconds\n      retentionPeriod: 7, // 7 days\n      aggregationLevels: ['minute', 'hour', 'day'],\n      alertThresholds: {\n        hitRate: 0.7,\n        responseTime: 1000,\n        errorRate: 0.05,\n        memoryUsage: 0.8\n      },\n      exportOptions: {\n        enabled: false,\n        formats: ['json'],\n        destination: './metrics'\n      },\n      ...config\n    };\n  }\n\n  private async collectMetrics(): Promise<void> {\n    const timestamp = new Date();\n    const newMetrics: MetricPoint[] = [];\n    \n    try {\n      // Collect search service metrics\n      const searchMetrics = this.cachedSearchService.getMetrics();\n      \n      newMetrics.push(...[\n        {\n          timestamp,\n          metric: 'hit_rate_overall',\n          value: searchMetrics.hitRates.overall,\n          tags: { layer: 'overall', source: 'search' },\n          source: 'cached_search_service'\n        },\n        {\n          timestamp,\n          metric: 'hit_rate_l1',\n          value: searchMetrics.hitRates.l1,\n          tags: { layer: 'l1', source: 'search' },\n          source: 'cached_search_service'\n        },\n        {\n          timestamp,\n          metric: 'hit_rate_l2',\n          value: searchMetrics.hitRates.l2,\n          tags: { layer: 'l2', source: 'search' },\n          source: 'cached_search_service'\n        },\n        {\n          timestamp,\n          metric: 'response_time_avg',\n          value: searchMetrics.performance.avgResponseTime,\n          tags: { type: 'average', source: 'search' },\n          source: 'cached_search_service'\n        },\n        {\n          timestamp,\n          metric: 'throughput',\n          value: searchMetrics.performance.throughput,\n          tags: { source: 'search' },\n          source: 'cached_search_service'\n        },\n        {\n          timestamp,\n          metric: 'total_queries',\n          value: searchMetrics.operations.totalQueries,\n          tags: { source: 'search' },\n          source: 'cached_search_service'\n        },\n        {\n          timestamp,\n          metric: 'cache_hits',\n          value: searchMetrics.operations.cacheHits,\n          tags: { source: 'search' },\n          source: 'cached_search_service'\n        },\n        {\n          timestamp,\n          metric: 'cache_misses',\n          value: searchMetrics.operations.cacheMisses,\n          tags: { source: 'search' },\n          source: 'cached_search_service'\n        },\n        {\n          timestamp,\n          metric: 'errors',\n          value: searchMetrics.operations.errors,\n          tags: { source: 'search' },\n          source: 'cached_search_service'\n        },\n        {\n          timestamp,\n          metric: 'memory_usage',\n          value: searchMetrics.storage.totalSize,\n          tags: { type: 'search_cache', source: 'search' },\n          source: 'cached_search_service'\n        }\n      ]);\n      \n      // Collect cache service metrics\n      const cacheStats = this.cacheService.stats();\n      \n      newMetrics.push(...[\n        {\n          timestamp,\n          metric: 'cache_size',\n          value: cacheStats.size,\n          tags: { type: 'general_cache', source: 'cache' },\n          source: 'cache_service'\n        },\n        {\n          timestamp,\n          metric: 'cache_hit_rate',\n          value: cacheStats.hitRate,\n          tags: { type: 'general_cache', source: 'cache' },\n          source: 'cache_service'\n        },\n        {\n          timestamp,\n          metric: 'evictions',\n          value: cacheStats.evictions,\n          tags: { type: 'general_cache', source: 'cache' },\n          source: 'cache_service'\n        },\n        {\n          timestamp,\n          metric: 'memory_usage',\n          value: cacheStats.memoryUsage || 0,\n          tags: { type: 'general_cache', source: 'cache' },\n          source: 'cache_service'\n        }\n      ]);\n      \n      // Collect HTTP cache metrics\n      const httpMetrics = this.cacheMiddleware.getMetrics();\n      \n      newMetrics.push(...[\n        {\n          timestamp,\n          metric: 'http_requests_total',\n          value: httpMetrics.requests.total,\n          tags: { source: 'http' },\n          source: 'cache_middleware'\n        },\n        {\n          timestamp,\n          metric: 'http_hits',\n          value: httpMetrics.requests.hits,\n          tags: { source: 'http' },\n          source: 'cache_middleware'\n        },\n        {\n          timestamp,\n          metric: 'http_misses',\n          value: httpMetrics.requests.misses,\n          tags: { source: 'http' },\n          source: 'cache_middleware'\n        },\n        {\n          timestamp,\n          metric: 'http_bypassed',\n          value: httpMetrics.requests.bypassed,\n          tags: { source: 'http' },\n          source: 'cache_middleware'\n        },\n        {\n          timestamp,\n          metric: 'bandwidth_saved',\n          value: httpMetrics.performance.bandwidthSaved,\n          tags: { source: 'http' },\n          source: 'cache_middleware'\n        }\n      ]);\n      \n      // Collect batch retriever metrics\n      const batchMetrics = this.batchRetriever.getMetrics();\n      \n      newMetrics.push(...[\n        {\n          timestamp,\n          metric: 'batch_requests',\n          value: batchMetrics.batchedRequests,\n          tags: { source: 'batch' },\n          source: 'batch_retriever'\n        },\n        {\n          timestamp,\n          metric: 'avg_batch_size',\n          value: batchMetrics.avgBatchSize,\n          tags: { source: 'batch' },\n          source: 'batch_retriever'\n        },\n        {\n          timestamp,\n          metric: 'performance_gain',\n          value: batchMetrics.performanceGain,\n          tags: { source: 'batch' },\n          source: 'batch_retriever'\n        }\n      ]);\n      \n      // Add all new metrics\n      this.metrics.push(...newMetrics);\n      \n      // Check for alert conditions\n      this.checkAlerts(newMetrics);\n      \n      // Emit metrics collected event\n      this.emit('metrics', newMetrics);\n      \n    } catch (error) {\n      console.error('Failed to collect metrics:', error);\n      this.emit('error', error);\n    }\n  }\n\n  private async aggregateMetrics(): Promise<void> {\n    for (const level of this.config.aggregationLevels) {\n      try {\n        const aggregated = await this.aggregateForTimeframe(level);\n        const key = `${level}_${aggregated.startTime.getTime()}`;\n        this.aggregatedMetrics.set(key, aggregated);\n      } catch (error) {\n        console.error(`Failed to aggregate ${level} metrics:`, error);\n      }\n    }\n  }\n\n  private async aggregateForTimeframe(timeframe: 'minute' | 'hour' | 'day'): Promise<AggregatedMetrics> {\n    const now = new Date();\n    let startTime: Date;\n    let endTime: Date;\n    \n    switch (timeframe) {\n      case 'minute':\n        startTime = new Date(now.getTime() - 60000);\n        endTime = now;\n        break;\n      case 'hour':\n        startTime = new Date(now.getTime() - 3600000);\n        endTime = now;\n        break;\n      case 'day':\n        startTime = new Date(now.getTime() - 86400000);\n        endTime = now;\n        break;\n    }\n    \n    const timeframeMetrics = this.getMetrics(startTime, endTime);\n    \n    return {\n      timeframe,\n      startTime,\n      endTime,\n      metrics: {\n        cache: this.aggregateCacheMetrics(timeframeMetrics),\n        search: this.aggregateSearchMetrics(timeframeMetrics),\n        http: this.aggregateHttpMetrics(timeframeMetrics),\n        batching: this.aggregateBatchingMetrics(timeframeMetrics)\n      }\n    };\n  }\n\n  private aggregateCacheMetrics(metrics: MetricPoint[]): any {\n    const hitRateMetrics = metrics.filter(m => m.metric === 'hit_rate_overall');\n    const responseTimeMetrics = metrics.filter(m => m.metric === 'response_time_avg');\n    const throughputMetrics = metrics.filter(m => m.metric === 'throughput');\n    const memoryMetrics = metrics.filter(m => m.metric === 'memory_usage');\n    const errorMetrics = metrics.filter(m => m.metric === 'errors');\n    \n    return {\n      hitRate: this.calculateStatistics(hitRateMetrics.map(m => m.value)),\n      responseTime: this.calculateStatistics(responseTimeMetrics.map(m => m.value)),\n      throughput: {\n        total: throughputMetrics.reduce((sum, m) => sum + m.value, 0),\n        avg: throughputMetrics.length > 0 ? \n          throughputMetrics.reduce((sum, m) => sum + m.value, 0) / throughputMetrics.length : 0,\n        peak: Math.max(...throughputMetrics.map(m => m.value), 0)\n      },\n      memoryUsage: {\n        ...this.calculateStatistics(memoryMetrics.map(m => m.value)),\n        current: memoryMetrics.length > 0 ? memoryMetrics[memoryMetrics.length - 1].value : 0\n      },\n      errorRate: this.calculateStatistics(errorMetrics.map(m => m.value))\n    };\n  }\n\n  private aggregateSearchMetrics(metrics: MetricPoint[]): any {\n    const queryMetrics = metrics.filter(m => m.metric === 'total_queries');\n    const errorMetrics = metrics.filter(m => m.metric === 'errors');\n    const responseTimeMetrics = metrics.filter(m => m.metric === 'response_time_avg');\n    \n    return {\n      queries: {\n        total: queryMetrics.reduce((sum, m) => sum + m.value, 0),\n        successful: queryMetrics.reduce((sum, m) => sum + m.value, 0) - errorMetrics.reduce((sum, m) => sum + m.value, 0),\n        failed: errorMetrics.reduce((sum, m) => sum + m.value, 0)\n      },\n      avgQueryTime: responseTimeMetrics.length > 0 ? \n        responseTimeMetrics.reduce((sum, m) => sum + m.value, 0) / responseTimeMetrics.length : 0,\n      popularQueries: [], // Would need to collect this data separately\n      categoryDistribution: {} // Would need to collect this data separately\n    };\n  }\n\n  private aggregateHttpMetrics(metrics: MetricPoint[]): any {\n    const requestMetrics = metrics.filter(m => m.metric === 'http_requests_total');\n    const hitMetrics = metrics.filter(m => m.metric === 'http_hits');\n    const missMetrics = metrics.filter(m => m.metric === 'http_misses');\n    const bandwidthMetrics = metrics.filter(m => m.metric === 'bandwidth_saved');\n    \n    return {\n      requests: {\n        total: requestMetrics.reduce((sum, m) => sum + m.value, 0),\n        hits: hitMetrics.reduce((sum, m) => sum + m.value, 0),\n        misses: missMetrics.reduce((sum, m) => sum + m.value, 0)\n      },\n      bandwidth: {\n        saved: bandwidthMetrics.reduce((sum, m) => sum + m.value, 0),\n        total: 0 // Would need to track total bandwidth\n      },\n      compressionRatio: 0 // Would need to calculate from compression metrics\n    };\n  }\n\n  private aggregateBatchingMetrics(metrics: MetricPoint[]): any {\n    const batchRequestMetrics = metrics.filter(m => m.metric === 'batch_requests');\n    const batchSizeMetrics = metrics.filter(m => m.metric === 'avg_batch_size');\n    const performanceGainMetrics = metrics.filter(m => m.metric === 'performance_gain');\n    \n    return {\n      batchedRequests: batchRequestMetrics.reduce((sum, m) => sum + m.value, 0),\n      avgBatchSize: batchSizeMetrics.length > 0 ? \n        batchSizeMetrics.reduce((sum, m) => sum + m.value, 0) / batchSizeMetrics.length : 0,\n      performanceGain: performanceGainMetrics.length > 0 ? \n        performanceGainMetrics.reduce((sum, m) => sum + m.value, 0) / performanceGainMetrics.length : 0\n    };\n  }\n\n  private calculateStatistics(values: number[]): { min: number; max: number; avg: number; p95: number } {\n    if (values.length === 0) {\n      return { min: 0, max: 0, avg: 0, p95: 0 };\n    }\n    \n    const sorted = values.slice().sort((a, b) => a - b);\n    const avg = values.reduce((sum, v) => sum + v, 0) / values.length;\n    const p95Index = Math.floor(sorted.length * 0.95);\n    \n    return {\n      min: sorted[0],\n      max: sorted[sorted.length - 1],\n      avg,\n      p95: sorted[p95Index] || sorted[sorted.length - 1]\n    };\n  }\n\n  private checkAlerts(metrics: MetricPoint[]): void {\n    for (const metric of metrics) {\n      this.checkMetricAlert(metric);\n    }\n  }\n\n  private checkMetricAlert(metric: MetricPoint): void {\n    let alertKey: string | null = null;\n    let threshold: number | null = null;\n    let severity: 'info' | 'warning' | 'error' | 'critical' = 'info';\n    \n    switch (metric.metric) {\n      case 'hit_rate_overall':\n        if (metric.value < this.config.alertThresholds.hitRate) {\n          alertKey = 'low_hit_rate';\n          threshold = this.config.alertThresholds.hitRate;\n          severity = metric.value < this.config.alertThresholds.hitRate * 0.8 ? 'error' : 'warning';\n        }\n        break;\n        \n      case 'response_time_avg':\n        if (metric.value > this.config.alertThresholds.responseTime) {\n          alertKey = 'high_response_time';\n          threshold = this.config.alertThresholds.responseTime;\n          severity = metric.value > this.config.alertThresholds.responseTime * 2 ? 'critical' : 'warning';\n        }\n        break;\n        \n      case 'memory_usage':\n        // Calculate as percentage of threshold\n        const memoryPercent = metric.value / (1024 * 1024 * 1024); // Convert to GB for comparison\n        if (memoryPercent > this.config.alertThresholds.memoryUsage) {\n          alertKey = 'high_memory_usage';\n          threshold = this.config.alertThresholds.memoryUsage;\n          severity = memoryPercent > 0.9 ? 'critical' : 'warning';\n        }\n        break;\n    }\n    \n    if (alertKey && threshold !== null) {\n      // Check if alert already exists\n      if (!this.activeAlerts.has(alertKey) || this.activeAlerts.get(alertKey)!.resolved) {\n        const alert: MetricsAlert = {\n          id: alertKey,\n          severity,\n          metric: metric.metric,\n          threshold,\n          currentValue: metric.value,\n          message: this.generateAlertMessage(metric.metric, metric.value, threshold),\n          timestamp: metric.timestamp\n        };\n        \n        this.activeAlerts.set(alertKey, alert);\n        this.emit('alert', alert);\n        \n        console.warn(`ðŸš¨ Alert: ${alert.message}`);\n      }\n    } else {\n      // Check if we should resolve existing alerts\n      this.resolveAlert(metric);\n    }\n  }\n\n  private resolveAlert(metric: MetricPoint): void {\n    const alertKey = this.getAlertKeyForMetric(metric.metric);\n    \n    if (alertKey && this.activeAlerts.has(alertKey)) {\n      const alert = this.activeAlerts.get(alertKey)!;\n      \n      if (!alert.resolved && this.shouldResolveAlert(metric, alert)) {\n        alert.resolved = true;\n        alert.resolvedAt = new Date();\n        \n        this.emit('alert_resolved', alert);\n        console.log(`âœ… Alert resolved: ${alert.message}`);\n      }\n    }\n  }\n\n  private getAlertKeyForMetric(metricName: string): string | null {\n    switch (metricName) {\n      case 'hit_rate_overall': return 'low_hit_rate';\n      case 'response_time_avg': return 'high_response_time';\n      case 'memory_usage': return 'high_memory_usage';\n      default: return null;\n    }\n  }\n\n  private shouldResolveAlert(metric: MetricPoint, alert: MetricsAlert): boolean {\n    switch (alert.metric) {\n      case 'hit_rate_overall':\n        return metric.value >= this.config.alertThresholds.hitRate;\n      case 'response_time_avg':\n        return metric.value <= this.config.alertThresholds.responseTime;\n      case 'memory_usage':\n        const memoryPercent = metric.value / (1024 * 1024 * 1024);\n        return memoryPercent <= this.config.alertThresholds.memoryUsage;\n      default:\n        return false;\n    }\n  }\n\n  private generateAlertMessage(metric: string, value: number, threshold: number): string {\n    switch (metric) {\n      case 'hit_rate_overall':\n        return `Cache hit rate (${(value * 100).toFixed(1)}%) below threshold (${(threshold * 100).toFixed(1)}%)`;\n      case 'response_time_avg':\n        return `Average response time (${value.toFixed(0)}ms) above threshold (${threshold}ms)`;\n      case 'memory_usage':\n        return `Memory usage (${(value / 1024 / 1024).toFixed(1)}MB) above threshold`;\n      default:\n        return `Metric ${metric} (${value}) outside threshold (${threshold})`;\n    }\n  }\n\n  private getRecentMetrics(duration: number): MetricPoint[] {\n    const cutoff = new Date(Date.now() - duration);\n    return this.metrics.filter(m => m.timestamp > cutoff);\n  }\n\n  private calculateOverallHealth(metrics: MetricPoint[]): any {\n    const hitRateMetrics = metrics.filter(m => m.metric === 'hit_rate_overall');\n    const responseTimeMetrics = metrics.filter(m => m.metric === 'response_time_avg');\n    const errorMetrics = metrics.filter(m => m.metric === 'errors');\n    \n    const avgHitRate = hitRateMetrics.length > 0 ? \n      hitRateMetrics.reduce((sum, m) => sum + m.value, 0) / hitRateMetrics.length : 0;\n    \n    const avgResponseTime = responseTimeMetrics.length > 0 ? \n      responseTimeMetrics.reduce((sum, m) => sum + m.value, 0) / responseTimeMetrics.length : 0;\n    \n    const totalErrors = errorMetrics.reduce((sum, m) => sum + m.value, 0);\n    \n    // Calculate health score (0-100)\n    let score = 100;\n    \n    if (avgHitRate < 0.9) score -= (0.9 - avgHitRate) * 50;\n    if (avgResponseTime > 500) score -= Math.min(40, (avgResponseTime - 500) / 50);\n    if (totalErrors > 0) score -= Math.min(20, totalErrors);\n    \n    score = Math.max(0, Math.min(100, score));\n    \n    const status = score >= 80 ? 'healthy' : score >= 60 ? 'degraded' : 'critical';\n    \n    return {\n      status,\n      score,\n      uptime: Date.now() - this.startTime.getTime()\n    };\n  }\n\n  private calculatePerformanceMetrics(metrics: MetricPoint[]): any {\n    const hitRateMetrics = metrics.filter(m => m.metric === 'hit_rate_overall');\n    const responseTimeMetrics = metrics.filter(m => m.metric === 'response_time_avg');\n    const throughputMetrics = metrics.filter(m => m.metric === 'throughput');\n    const errorMetrics = metrics.filter(m => m.metric === 'errors');\n    const totalQueries = metrics.filter(m => m.metric === 'total_queries');\n    \n    return {\n      hitRate: hitRateMetrics.length > 0 ? \n        hitRateMetrics.reduce((sum, m) => sum + m.value, 0) / hitRateMetrics.length : 0,\n      avgResponseTime: responseTimeMetrics.length > 0 ? \n        responseTimeMetrics.reduce((sum, m) => sum + m.value, 0) / responseTimeMetrics.length : 0,\n      throughput: throughputMetrics.length > 0 ? \n        throughputMetrics.reduce((sum, m) => sum + m.value, 0) / throughputMetrics.length : 0,\n      errorRate: totalQueries.length > 0 ? \n        errorMetrics.reduce((sum, m) => sum + m.value, 0) / totalQueries.reduce((sum, m) => sum + m.value, 0) : 0\n    };\n  }\n\n  private calculateTrends(): any {\n    // Simple trend calculation based on recent vs older metrics\n    const recent = this.getRecentMetrics(300000); // Last 5 minutes\n    const older = this.getRecentMetrics(900000).filter(m => // 10-15 minutes ago\n      m.timestamp < new Date(Date.now() - 600000)\n    );\n    \n    return {\n      hitRateTrend: this.compareTrend(recent, older, 'hit_rate_overall', true),\n      responseTrend: this.compareTrend(recent, older, 'response_time_avg', false),\n      throughputTrend: this.compareTrend(recent, older, 'throughput', true)\n    };\n  }\n\n  private compareTrend(\n    recent: MetricPoint[], \n    older: MetricPoint[], \n    metric: string, \n    higherIsBetter: boolean\n  ): 'improving' | 'stable' | 'declining' {\n    const recentValues = recent.filter(m => m.metric === metric).map(m => m.value);\n    const olderValues = older.filter(m => m.metric === metric).map(m => m.value);\n    \n    if (recentValues.length === 0 || olderValues.length === 0) {\n      return 'stable';\n    }\n    \n    const recentAvg = recentValues.reduce((sum, v) => sum + v, 0) / recentValues.length;\n    const olderAvg = olderValues.reduce((sum, v) => sum + v, 0) / olderValues.length;\n    \n    const threshold = 0.05; // 5% change threshold\n    const change = (recentAvg - olderAvg) / olderAvg;\n    \n    if (Math.abs(change) < threshold) {\n      return 'stable';\n    }\n    \n    const isImproving = higherIsBetter ? change > 0 : change < 0;\n    return isImproving ? 'improving' : 'declining';\n  }\n\n  private getTopIssues(): string[] {\n    const issues: string[] = [];\n    const activeAlerts = this.getActiveAlerts();\n    \n    for (const alert of activeAlerts) {\n      if (alert.severity === 'critical' || alert.severity === 'error') {\n        issues.push(alert.message);\n      }\n    }\n    \n    return issues.slice(0, 5); // Top 5 issues\n  }\n\n  private generateRecommendations(metrics: MetricPoint[]): string[] {\n    const recommendations: string[] = [];\n    const performance = this.calculatePerformanceMetrics(metrics);\n    \n    if (performance.hitRate < 0.8) {\n      recommendations.push('Consider increasing cache TTL or implementing more aggressive warming');\n    }\n    \n    if (performance.avgResponseTime > 800) {\n      recommendations.push('Optimize query processing or add more cache layers');\n    }\n    \n    if (performance.errorRate > 0.03) {\n      recommendations.push('Investigate error patterns and improve error handling');\n    }\n    \n    return recommendations;\n  }\n\n  private async exportJSON(metrics: MetricPoint[]): Promise<void> {\n    // Implementation would write to file system\n    console.log('ðŸ“Š Exporting metrics to JSON format');\n  }\n\n  private async exportCSV(metrics: MetricPoint[]): Promise<void> {\n    // Implementation would write to file system\n    console.log('ðŸ“Š Exporting metrics to CSV format');\n  }\n\n  private async exportPrometheus(): Promise<void> {\n    // Implementation would expose Prometheus endpoint\n    console.log('ðŸ“Š Exporting metrics to Prometheus format');\n  }\n}\n\nexport default CacheMetricsCollector;